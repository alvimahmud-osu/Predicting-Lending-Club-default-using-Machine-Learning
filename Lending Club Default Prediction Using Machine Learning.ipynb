{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plotting options\n",
    "mpl.style.use('ggplot')\n",
    "sns.set(style='whitegrid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_good=pd.DataFrame()\n",
    "for chunk in pd.read_csv(r'D:\\Adv SAS\\lending-club\\accepted_2007_to_2018Q3.csv', chunksize=50000, low_memory= False):\n",
    "    loan_good = pd.concat([loan_good, chunk], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only charged off and fully paid loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans = loan_good.loc[loan_good['loan_status'].isin(['Fully Paid', 'Charged Off'])]\n",
    "loans=loans.set_index('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For feature selection, Drop columns which has 75% or more missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_fractions = loans.isnull().mean().sort_values(ascending=False)\n",
    "plt.figure(figsize=(6,3), dpi=90)\n",
    "missing_fractions.plot.hist(bins=20)\n",
    "plt.title('Histogram of Feature Incompleteness')\n",
    "plt.xlabel('Fraction of data missing')\n",
    "plt.ylabel('Feature count')\n",
    "drop_list = sorted(list(missing_fractions[missing_fractions > 0.25].index))\n",
    "len(drop_list)\n",
    "loans.drop(labels=drop_list, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix the variables with datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans['issue_d'].isnull().any()\n",
    "import datetime\n",
    "loans['issue_d']=pd.to_datetime(loans['issue_d'])\n",
    "loans['earliest_cr_line'] = pd.to_datetime(loans['earliest_cr_line'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep Variables that will be known at the time of approving loan only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_list = ['addr_state', 'annual_inc', 'application_type', 'dti', 'earliest_cr_line', 'emp_length', 'emp_title', 'fico_range_high', 'fico_range_low', 'home_ownership', 'id', 'initial_list_status', 'installment', 'int_rate', 'issue_d', 'loan_amnt', 'loan_status', 'mort_acc', 'open_acc', 'pub_rec', 'pub_rec_bankruptcies', 'purpose', 'revol_bal', 'revol_util', 'sub_grade', 'term', 'total_acc', 'verification_status']\n",
    "drop_list = [col for col in loans.columns if col not in keep_list]\n",
    "loans.drop(labels=drop_list, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering: Convert Employment title to numeric (We will treat this as a numerical variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q= loans.groupby('emp_title').size()\n",
    "q=q/len(loans)\n",
    "loans[\"emp_ttl\"]= loans.emp_title.map(q)\n",
    "loans=loans.drop('emp_title', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the Target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def status_to_numeric(y):\n",
    "    if y=='Fully Paid':\n",
    "        return 0\n",
    "    if y=='Charged Off':\n",
    "        return 1\n",
    "loans['loan_status'] = loans['loan_status'].apply(status_to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering: Convert Grade to Numeric values (We will treat this as a numerical variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_to_numeric(yy):\n",
    "    if yy=='A1':\n",
    "        return 1\n",
    "    if yy=='A2':\n",
    "        return 2\n",
    "    if yy=='A3':\n",
    "        return 3\n",
    "    if yy=='A4':\n",
    "        return 4\n",
    "    if yy=='A5':\n",
    "        return 5\n",
    "    if yy=='B1':\n",
    "        return 6\n",
    "    if yy=='B2':\n",
    "        return 7\n",
    "    if yy=='B3':\n",
    "        return 8\n",
    "    if yy=='B4':\n",
    "        return 9\n",
    "    if yy=='B5':\n",
    "        return 10\n",
    "    if yy=='C1':\n",
    "        return 11\n",
    "    if yy=='C2':\n",
    "        return 12\n",
    "    if yy=='C3':\n",
    "        return 13\n",
    "    if yy=='C4':\n",
    "        return 14\n",
    "    if yy=='C5':\n",
    "        return 15\n",
    "    if yy=='D1':\n",
    "        return 16\n",
    "    if yy=='D2':\n",
    "        return 17\n",
    "    if yy=='D3':\n",
    "        return 18\n",
    "    if yy=='D4':\n",
    "        return 19\n",
    "    if yy=='D5':\n",
    "        return 20\n",
    "    if yy=='E1':\n",
    "        return 21\n",
    "    if yy=='E2':\n",
    "        return 22\n",
    "    if yy=='E3':\n",
    "        return 23\n",
    "    if yy=='E4':\n",
    "        return 24\n",
    "    if yy=='E5':\n",
    "        return 25\n",
    "    if yy=='F1':\n",
    "        return 26\n",
    "    if yy=='F2':\n",
    "        return 27\n",
    "    if yy=='F3':\n",
    "        return 28\n",
    "    if yy=='F4':\n",
    "        return 29\n",
    "    if yy=='F5':\n",
    "        return 30\n",
    "    if yy=='G1':\n",
    "        return 31\n",
    "    if yy=='G2':\n",
    "        return 32\n",
    "    if yy=='G3':\n",
    "        return 33\n",
    "    if yy=='G4':\n",
    "        return 34\n",
    "    if yy=='G5':\n",
    "        return 35\n",
    "loans['Grade'] = loans['sub_grade'].apply(grade_to_numeric)   \n",
    "loans = loans.drop('sub_grade', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering: Fix Employment length column, convert the values to float (We will treat it as categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_to_numeric(yl):\n",
    "    if yl=='1 year':\n",
    "        return 1\n",
    "    if yl=='2 years':\n",
    "        return 2\n",
    "    if yl=='3 years':\n",
    "        return 3\n",
    "    if yl=='4 years':\n",
    "        return 4\n",
    "    if yl=='5 years':\n",
    "        return 5\n",
    "    if yl=='6 years':\n",
    "        return 6\n",
    "    if yl=='7 years':\n",
    "        return 7\n",
    "    if yl=='8 years':\n",
    "        return 8\n",
    "    if yl=='9 years':\n",
    "        return 9\n",
    "    if yl=='10 years':\n",
    "        return 10\n",
    "    if yl=='< 1 year':\n",
    "        return 0.5\n",
    "    if yl=='10+ years':\n",
    "        return 11\n",
    "loans['em_length'] = loans['emp_length'].apply(length_to_numeric)\n",
    "loans = loans.drop('emp_length', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Creation: Create the credit length column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans['credit_length']=loans['issue_d']-loans['earliest_cr_line']\n",
    "loans['credit_length']=loans['credit_length'].dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering: Convert the Term and Employment length into numerical type columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans['term2']=loans['term'].str.extract(\"(\\d*\\.?\\d+)\", expand=True).astype(int)\n",
    "loans=loans.drop('term',axis=1)\n",
    "loans['emp_len']=loans['em_length'].apply(lambda x: 0.5 if x==-0.5 else x)\n",
    "loans=loans.drop('em_length',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few values in the earliest credit line column were greater than 2018 (probably due to mistake), we filter those columns out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans['earliest_cr_yr']=loans.earliest_cr_line.dt.year\n",
    "loans=loans[loans.earliest_cr_yr < 2018]\n",
    "loans=loans.drop(['issue_d','earliest_cr_line', 'earliest_cr_yr'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a saving point in this time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loans.to_csv(r'D:\\Adv SAS\\lending-club\\accepted\\Loans_processed.csv',index=True)\n",
    "loans= pd.read_csv(r'D:\\Adv SAS\\lending-club\\accepted\\Loans_processed.csv')\n",
    "loans=loans.drop('Unnamed: 0', axis=1).set_index('id')\n",
    "loans= loans.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import standardscaler\n",
    "SC= standardscaler()\n",
    "num_cols = loans.columns[loans.dtypes.apply(lambda c: np.issubdtype(c, np.number))]\n",
    "num_cols=num_cols.drop(['loan_status'])\n",
    "loans[num_cols] = SC(loans[num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resize the dataframe to reduce memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(props):\n",
    "    start_mem_usg = props.memory_usage().sum() / 1024**2 \n",
    "    print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n",
    "    NAlist = [] # Keeps track of columns that have missing values filled in. \n",
    "    for col in props.columns:\n",
    "        if props[col].dtype != object:  # Exclude strings\n",
    "            \n",
    "            # Print current column type\n",
    "            print(\"******************************\")\n",
    "            print(\"Column: \",col)\n",
    "            print(\"dtype before: \",props[col].dtype)\n",
    "            \n",
    "            # make variables for Int, max and min\n",
    "            IsInt = False\n",
    "            mx = props[col].max()\n",
    "            mn = props[col].min()\n",
    "            \n",
    "            # Integer does not support NA, therefore, NA needs to be filled\n",
    "            if not np.isfinite(props[col]).all(): \n",
    "                NAlist.append(col)\n",
    "                props[col].fillna(mn-1,inplace=True)  \n",
    "                   \n",
    "            # test if column can be converted to an integer\n",
    "            asint = props[col].fillna(0).astype(np.int64)\n",
    "            result = (props[col] - asint)\n",
    "            result = result.sum()\n",
    "            if result > -0.01 and result < 0.01:\n",
    "                IsInt = True\n",
    "\n",
    "            \n",
    "            # Make Integer/unsigned Integer datatypes\n",
    "            if IsInt:\n",
    "                if mn >= 0:\n",
    "                    if mx < 255:\n",
    "                        props[col] = props[col].astype(np.uint8)\n",
    "                    elif mx < 65535:\n",
    "                        props[col] = props[col].astype(np.uint16)\n",
    "                    elif mx < 4294967295:\n",
    "                        props[col] = props[col].astype(np.uint32)\n",
    "                    else:\n",
    "                        props[col] = props[col].astype(np.uint64)\n",
    "                else:\n",
    "                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n",
    "                        props[col] = props[col].astype(np.int8)\n",
    "                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n",
    "                        props[col] = props[col].astype(np.int16)\n",
    "                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n",
    "                        props[col] = props[col].astype(np.int32)\n",
    "                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n",
    "                        props[col] = props[col].astype(np.int64)    \n",
    "            \n",
    "            # Make float datatypes 32 bit\n",
    "            else:\n",
    "                props[col] = props[col].astype(np.float32)\n",
    "            \n",
    "            # Print new column type\n",
    "            print(\"dtype after: \",props[col].dtype)\n",
    "            print(\"******************************\")\n",
    "    \n",
    "    # Print final result\n",
    "    print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n",
    "    mem_usg = props.memory_usage().sum() / 1024**2 \n",
    "    print(\"Memory usage is: \",mem_usg,\" MB\")\n",
    "    print(\"This is \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n",
    "    return props, NAlist\n",
    "\n",
    "props, NAlist = reduce_mem_usage(loans)\n",
    "print(\"_________________\")\n",
    "print(\"\")\n",
    "print(\"Warning: the following columns have missing values filled with 'df['column_name'].min() -1': \")\n",
    "print(\"_________________\")\n",
    "print(\"\")\n",
    "print(NAlist)\n",
    "#props.to_csv(r'D:\\Adv SAS\\lending-club\\accepted\\Loans_processed.csv',index=True)\n",
    "loans= props.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data (3 way for LightGBM & XGBoost), 2 way for Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = np.split(loans.sample(frac=1), [int(.6*len(loans)), int(.8*len(loans))])\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(loans.drop('loan_status', axis=1),loans.loan_status, test_size=0.30, random_state=420)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smoteing and creating a second save point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "smote_nc = SMOTENC(categorical_features=[3,5,6,7,16,17,23,24], random_state=420)\n",
    "X, y = smote_nc.fit_resample(X_train, y_train)\n",
    "Xx, Yy = smote_nc.fit_resample(train.drop('loan_status', axis=1),train.loan_status)\n",
    "np.save(r'D:\\Adv SAS\\lending-club\\accepted\\Loans_balanced.npy', X)\n",
    "np.save(r'D:\\Adv SAS\\lending-club\\accepted\\Loans_status.npy', y)\n",
    "np.save(r'D:\\Adv SAS\\lending-club\\accepted\\Loans_balanced2.npy', Xx)\n",
    "np.save(r'D:\\Adv SAS\\lending-club\\accepted\\Loans_status2.npy', Yy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labeling categorical features for using in lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "xtr= pd.DataFrame(X)\n",
    "xtr.columns= X_train.columns\n",
    "xtr2= pd.DataFrame(Xx)\n",
    "xtr2.columns= X_train.columns\n",
    "\n",
    "class MultiColumnLabelEncoder:\n",
    "    def __init__(self,columns = None):\n",
    "        self.columns = columns # array of column names to encode\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self # not relevant here\n",
    "\n",
    "    def transform(self,X):\n",
    "        '''\n",
    "        Transforms columns of X specified in self.columns using\n",
    "        LabelEncoder(). If no columns specified, transforms all\n",
    "        columns in X.\n",
    "        '''\n",
    "        output = X.copy()\n",
    "        if self.columns is not None:\n",
    "            for col in self.columns:\n",
    "                output[col] = LabelEncoder().fit_transform(output[col])\n",
    "        else:\n",
    "            for colname,col in output.iteritems():\n",
    "                output[colname] = LabelEncoder().fit_transform(col)\n",
    "        return output\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        return self.fit(X,y).transform(X)\n",
    "\n",
    "X1= MultiColumnLabelEncoder(columns = [ 'application_type','home_ownership', 'verification_status','addr_state', 'initial_list_status', 'purpose']).fit_transform(xtr).values\n",
    "Xt1= MultiColumnLabelEncoder(columns = [ 'application_type','home_ownership', 'verification_status','addr_state', 'initial_list_status', 'purpose']).fit_transform(X_test).values\n",
    "X2= MultiColumnLabelEncoder(columns = [ 'application_type','home_ownership', 'verification_status','addr_state', 'initial_list_status', 'purpose']).fit_transform(xtr2).values\n",
    "Xv= MultiColumnLabelEncoder(columns = [ 'application_type','home_ownership', 'verification_status','addr_state', 'initial_list_status', 'purpose']).fit_transform(validate.drop('loan_status',axis=1)).values\n",
    "Xt2= MultiColumnLabelEncoder(columns = [ 'application_type','home_ownership', 'verification_status','addr_state', 'initial_list_status', 'purpose']).fit_transform(test.drop('loan_status',axis=1)).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM With Early stopping and Prediction using the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "d_train = lgb.Dataset(X2, label=Yy, categorical_feature=[3,5,6,7,16,17,23,24], free_raw_data=False)\n",
    "d_val = lgb.Dataset(Xv, label=validate.loan_status.values, reference=d_train)\n",
    "param = {'num_leaves':1000, 'objective':'binary','max_depth':30,'learning_rate':.1,'max_bin':800,\n",
    "         'min_data_in_leaf': 500, 'task':'predict', 'feature_fraction':0.7,\"bagging_fraction\" : 0.6,\n",
    "        \"bagging_freq\" : 1, \"bagging_seed\" : 2018,\n",
    "        \"verbosity\" : 4, \"min_child_samples\":30}\n",
    "param['metric'] = ['auc', 'binary_logloss']\n",
    "clf = lgb.train(param, d_train, 2000,valid_sets=d_val, early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(Xt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert into binary values\n",
    "for i in range(len(Xt2)):\n",
    "    if y_pred[i]>=.5:       # setting threshold to .5\n",
    "       y_pred[i]=1\n",
    "    else:  \n",
    "       y_pred[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cmbl = confusion_matrix(test.loan_status, y_pred)\n",
    "#Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy=accuracy_score(y_pred,test.loan_status)\n",
    "\n",
    "print(cmbl)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dummy variables for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xg= pd.get_dummies(xtr2,columns = [ 'application_type','home_ownership', 'verification_status','addr_state', 'initial_list_status', 'purpose', 'term2'],drop_first=True)\n",
    "Xtg= pd.get_dummies(test.drop('loan_status',axis=1),columns = [ 'application_type','home_ownership', 'verification_status','addr_state', 'initial_list_status', 'purpose', 'term2'],drop_first=True)\n",
    "Xvg= pd.get_dummies(validate.drop('loan_status',axis=1),columns = [ 'application_type','home_ownership', 'verification_status','addr_state', 'initial_list_status', 'purpose', 'term2'],drop_first=True).values\n",
    "# Get missing columns in the training test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get missing columns in the training test on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_cols = set( Xg.columns ) - set( Xtg.columns )\n",
    "# Add a missing column in test set with default value equal to 0\n",
    "for c in missing_cols:\n",
    "    Xtg[c] = 0\n",
    "# Ensure the order of column in the test set is in the same order than in train set\n",
    "Xtg = Xtg[Xg.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost with early stopping and Prediction using the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "dtrain = xgb.DMatrix(Xg.values, label=Yy)\n",
    "dval = xgb.DMatrix(Xvg, label=validate.loan_status.values)\n",
    "dtest = xgb.DMatrix(Xtg.values)\n",
    "eval_set = [(Xg, Yy), (Xvg, validate.loan_status.values)]\n",
    "\n",
    "param = {'max_depth':30, 'silent':1, 'objective':'binary:logistic', 'subsample':0.5,\"booster\": 'dart', \n",
    "         'eval_metric':[\"error\",\"logloss\"],'learning_rate': 0.3, 'seed':420}\n",
    "\n",
    "model= xgb.train(dtrain=dtrain,params= param,num_boost_round=150,early_stopping_rounds=20,\n",
    "                        evals= [(dval, 'eval'), (dtrain, 'train')], verbose_eval=10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xg = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [round(value) for value in y_pred_xg]\n",
    "accuracy_xg2 = accuracy_score(test.loan_status, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy_xg2 * 100.0))\n",
    "cmxg = confusion_matrix(test.loan_status, predictions)\n",
    "print(\"TN,FN,FP,TP\" % (cmxg.ravel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistics Regression built on Keras with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "Xlr= pd.get_dummies(xtr,columns = [ 'application_type','home_ownership', 'verification_status','addr_state', 'initial_list_status', 'purpose', 'term2'],drop_first=True)\n",
    "y=pd.DataFrame(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ylr=pd.get_dummies(y, prefix='loan_status') #Dummycode the target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xlr_test= pd.get_dummies(X_test,columns = [ 'application_type','home_ownership', 'verification_status','addr_state', 'initial_list_status', 'purpose', 'term2'],drop_first=True)\n",
    "Ylr_test=pd.get_dummies(y_test, prefix='loan_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Activation\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.regularizers import L1L2\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model on a single layer with regularization and without output activation to make the model a GLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = L1L2(l1=0.01, l2=0.01)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1, activation='relu', kernel_regularizer=reg, input_dim=Xlr.shape[1]))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metric=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Tensors from the training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain=tf.convert_to_tensor(Xlr.values, np.float32)\n",
    "Ytrain=tf.convert_to_tensor(Ylr.values, np.float32)\n",
    "Xtest=tf.convert_to_tensor(Xlr_test.values, np.float32)\n",
    "Ytest=tf.convert_to_tensor(Ylr_test.values, np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit model with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min',patience=10, verbose=1)\n",
    "history = model.fit(Xtrain,Ytrain , batch_size=50, epochs=200, verbose=2, validation_split=0.2, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(Xtest, Ytest, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test acc:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
